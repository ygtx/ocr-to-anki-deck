import os
import json
import tempfile
from pathlib import Path
from typing import List, Dict, Any, Optional
from openai import OpenAI
from gtts import gTTS
from deep_translator import MyMemoryTranslator
from genanki import Model, Note, Deck, Package
import csv
import re
import time
import random

class BaseDeckBuilder:
    def __init__(self, output_dir: str, deck_name: str, use_paiboon_correction: bool = True):
        self.output_dir = Path(output_dir)
        self.deck_name = deck_name
        self.client = OpenAI()
        self.temp_dir = Path(tempfile.mkdtemp())
        self.use_paiboon_correction = use_paiboon_correction
        
    def build_rules(self) -> str:
        """Paiboonä¿®æ­£ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å‹•çš„ã«ç”Ÿæˆï¼ˆä¾‹å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯TSVã‹ã‚‰è‡ªå‹•æŒ¿å…¥ï¼‰"""
        # ä¾‹å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        default_exceptions = [
            ("à¸‚à¸­à¸šà¸„à¸¸à¸“", "khoÌ€p khun"),
            ("à¸‚à¸­à¹‚à¸—à¸©", "khÇw thÃ´ot"),
            ("à¹„à¸¡à¹ˆà¹€à¸›à¹‡à¸™à¹„à¸£", "mÃ¢y pen ray"),
            ("à¸¢à¸´à¸™à¸”à¸µà¸—à¸µà¹ˆà¹„à¸”à¹‰à¸£à¸¹à¹‰à¸ˆà¸±à¸", "yin dii thÃ®i dÃ¢y rÃºu cÃ k"),
            ("à¸Šà¸·à¹ˆà¸­à¸­à¸°à¹„à¸£", "chÃ»Ê‰ aray"),
            ("à¹€à¸›à¹‡à¸™à¸¢à¸±à¸‡à¹„à¸‡à¸šà¹‰à¸²à¸‡", "pen yÃ Å‹Å‹ay bÃ¢aÅ‹"),
            ("à¹€à¸£à¸·à¹ˆà¸­à¸¢ à¹†", "rÊ‰Ì‚ay rÊ‰Ì‚ay"),
        ]
        # TSVã‹ã‚‰ä¾‹å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡º
        tsv_path = Path("data/output/system/paiboon_diff.tsv")
        exceptions = []
        seen = set()
        if tsv_path.exists():
            with open(tsv_path, encoding="utf-8") as f:
                reader = csv.DictReader(f, delimiter="\t")
                for row in reader:
                    if row["type"] == "mismatch" and row["gold_paiboon"]:
                        key = (row["thai"], row["gold_paiboon"])
                        if key not in seen:
                            exceptions.append(key)
                            seen.add(key)
        # æ—¢å­˜ä¾‹å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒtsvã«ç„¡ã‘ã‚Œã°è¿½è¨˜
        new_lines = []
        for thai, paiboon in default_exceptions:
            if (thai, paiboon) not in seen:
                new_lines.append({
                    "thai": thai,
                    "gold_paiboon": paiboon,
                    "generated_paiboon": "",
                    "type": "mismatch"
                })
                exceptions.append((thai, paiboon))
        if new_lines:
            # è¿½è¨˜
            write_header = not tsv_path.exists()
            with open(tsv_path, "a", encoding="utf-8", newline='') as f:
                writer = csv.DictWriter(f, fieldnames=["thai", "gold_paiboon", "generated_paiboon", "type"], delimiter="\t")
                if write_header:
                    writer.writeheader()
                for row in new_lines:
                    writer.writerow(row)
        # ä¾‹å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³æ–‡è¨€ç”Ÿæˆ
        if exceptions:
            exception_lines = [f"   - {thai} â†’ {paiboon}" for thai, paiboon in exceptions]
            exception_text = "\n".join(exception_lines)
        else:
            exception_text = "   - ä¾‹å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³ãªã—"
        # ãƒ«ãƒ¼ãƒ«æœ¬ä½“
        rules = f"""
ã‚ãªãŸã¯ã‚¿ã‚¤æ–‡å­—ã®Paiboonå¼ãƒ­ãƒ¼ãƒå­—è¡¨è¨˜ã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦ã€Paiboonè¡¨è¨˜ã®èª¤ã‚Šã‚’ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚

ã€ä¿®æ­£æ‰‹é †ã€‘
1. ã¾ãšã€ä¾‹å¤–ãƒªã‚¹ãƒˆã«å®Œå…¨ä¸€è‡´ã™ã‚‹ "thai" ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒã‚ã‚‹å ´åˆã¯ã€"paiboon" ã‚’ä¾‹å¤–ãƒªã‚¹ãƒˆã«æ›¸ã‹ã‚Œã¦ã„ã‚‹æ­£è§£ã«å¿…ãšç½®ãæ›ãˆã¦ãã ã•ã„ï¼ˆå¾®å¦™ãªä¸€è‡´ã§ã¯ãªãã€å®Œå…¨ä¸€è‡´ãƒ™ãƒ¼ã‚¹ï¼‰ã€‚
2. ä¾‹å¤–ã«ä¸€è‡´ã—ãªã„å ´åˆã¯ã€ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã«å³å¯†ã«å¾“ã£ã¦ä¿®æ­£ã‚’è¡Œã£ã¦ãã ã•ã„ï¼ˆè‡ªç”±è¡¨ç¾ã¯ä¸€åˆ‡ç¦æ­¢ï¼‰ã€‚

ã€Paiboon ä¿®æ­£ãƒ«ãƒ¼ãƒ«ã€‘
- å£°èª¿è¨˜å·ã¯æ¯éŸ³ã®ä¸Šã«1å›ã®ã¿é…ç½®ï¼ˆä¾‹ï¼škhÃ²Ã²p â†’ khÃ²pï¼‰
- é•·æ¯éŸ³ã®é‡è¤‡ã¯ç¦æ­¢ï¼ˆä¾‹ï¼škhÃ²Ã²p â†’ khÃ²pï¼‰
- æ¯éŸ³ãƒ»å­éŸ³è¨˜å·ã¯Paiboonæ¨™æº–ã‚’ç”¨ã„ã‚‹ï¼ˆä¾‹ï¼šÊ‰Ì‚Ê‰ â†’ chÃ»Ê‰ ã¾ãŸã¯ ueï¼‰
- çŸ­æ¯éŸ³ï¼ˆÄƒï¼‰ã¨å£°èª¿æ¯éŸ³ï¼ˆÇï¼‰ã¯æ˜ç¢ºã«åŒºåˆ¥
- "mÃ¢y" ã¯å¸¸ã«ç¬¬3å£°ï¼ˆyã®ä¸Šã«é‡ã‚¢ã‚¯ã‚»ãƒ³ãƒˆï¼‰
- æ–‡è„ˆã«å¿œã˜ã¦ "dÃ¢i"ï¼ˆcanï¼‰ã¨ "dÃ¢y"ï¼ˆã§ããŸï¼‰ã‚’ä½¿ã„åˆ†ã‘ã‚‹ï¼ˆæ„å‘³ã®æ›–æ˜§ãªå ´åˆã¯ "dÃ¢y" ã‚’å„ªå…ˆï¼‰
- æœ€çµ‚å­éŸ³ãŒ "b" ã®å ´åˆã¯ "p" ã«å¤‰æ›ï¼ˆä¾‹ï¼škhÃ²b khun â†’ khoÌ€p khunï¼‰
- éŸ³ç¯€ã®å†æ§‹æˆã¯ç¦æ­¢ï¼ˆä¾‹ï¼šyÃ Å‹Å‹ay â†’ yanjay ã¯NGï¼‰

ã€ä¾‹å¤–ãƒªã‚¹ãƒˆï¼ˆå®Œå…¨ä¸€è‡´é©ç”¨ï¼‰ã€‘
{exception_text}

ã€å…¥åŠ›å½¢å¼ã€‘
{{
  "thai": "ã‚¿ã‚¤èªã®æ–‡å­—åˆ—",
  "paiboon": "OCRã§å¾—ã‚‰ã‚ŒãŸPaiboonå¼ãƒ­ãƒ¼ãƒå­—",
  "meaning": "æ—¥æœ¬èªã®æ„å‘³"
}}

ã€å‡ºåŠ›å½¢å¼ã€‘
{{
  "thai": "ï¼ˆå¤‰æ›´ãªã—ï¼‰",
  "paiboon": "ä¿®æ­£å¾Œã®Paiboonè¡¨è¨˜ï¼ˆãƒ«ãƒ¼ãƒ«ã¾ãŸã¯ä¾‹å¤–ã«å¾“ã£ã¦ä¿®æ­£ï¼‰",
  "meaning": "ï¼ˆå¤‰æ›´ãªã—ï¼‰"
}}

âš ï¸ ãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦ã„ãªã„ä¿®æ­£ã€å‰µé€ çš„ãªå‡ºåŠ›ã€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆé€¸è„±ã¯ä¸€åˆ‡ç¦æ­¢ã§ã™ã€‚
"""
        return rules

    def _save_ocr_data(self, data: List[Dict[str, str]]) -> Path:
        """OCRãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        temp_file = self.temp_dir / "ocr_data.json"
        with open(temp_file, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        return temp_file

    def paiboon_normalize(self, paiboon: str, entry: dict = None) -> str:
        import re
        # ä»£è¡¨çš„ãªIPAèª¤OCRè£œæ­£
        ipa_map = {
            'nÉ¯Ì€ng': 'nÊ‰Ì€ng',
            'sÊ‰Ì€Ê‰': 'sÊ‰Ê‰',
            # å¿…è¦ã«å¿œã˜ã¦è¿½åŠ 
        }
        for wrong, correct in ipa_map.items():
            paiboon = paiboon.replace(wrong, correct)
        # æœ€çµ‚bâ†’p
        paiboon = re.sub(r'b$', 'p', paiboon)
        # mÃ¢yã¯å¸¸ã«ç¬¬3å£°
        paiboon = re.sub(r'mÃ¢y', 'mÃ¢y', paiboon)
        # dÃ¢i/dÃ¢yã¯æ„å‘³ã§åˆ†ã‘ã‚‹ãŒã€æ›–æ˜§ãªã‚‰dÃ¢y
        paiboon = re.sub(r'dÃ¢i', 'dÃ¢y', paiboon)
        return paiboon

    def _correct_paiboon(self, data: List[Dict[str, str]]) -> List[Dict[str, str]]:
        """ã‚¿ã‚¤èªã‚’ãƒ™ãƒ¼ã‚¹ã«ã—ãŸPaiboonå¼ãƒ­ãƒ¼ãƒå­—ã®ä¿®æ­£ï¼ˆFunction Calling+ãƒªãƒˆãƒ©ã‚¤1å›+è©³ç´°ãƒ­ã‚°+content Noneå¯¾å¿œ+ã‚¿ã‚¤æ–‡å­—åˆ¤å®šï¼‰"""
        if not data:
            print("âš ï¸ ä¿®æ­£å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
            return []
        corrected_data = []
        rules = self.build_rules()
        function_schema = {
            "name": "fix_paiboon",
            "description": "Paiboon è¡¨è¨˜ã‚’ä¿®æ­£ã—ã¦è¿”ã™",
            "parameters": {
                "type": "object",
                "properties": {
                    "thai": {"type": "string"},
                    "paiboon": {"type": "string"},
                    "meaning": {"type": "string"}
                },
                "required": ["thai", "paiboon", "meaning"]
            }
        }
        for entry in data:
            print(f"\n---\n[å‡¦ç†é–‹å§‹] å…¥åŠ›ãƒ‡ãƒ¼ã‚¿: {json.dumps(entry, ensure_ascii=False)}")
            # Thaiãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«ã‚¿ã‚¤æ–‡å­—ãŒ1æ–‡å­—ã‚‚å«ã¾ã‚Œãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            if not re.search(r'[\u0E00-\u0E7F]', entry.get("thai", "")):
                print(f"âš ï¸ Thaiãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«ã‚¿ã‚¤æ–‡å­—ãŒå«ã¾ã‚Œã¦ã„ãªã„ãŸã‚ã‚¹ã‚­ãƒƒãƒ—: {json.dumps(entry, ensure_ascii=False)}")
                corrected_data.append(entry)
                continue
            if not entry.get("paiboon"):
                print(f"âš ï¸ paiboon=None or empty entry: {json.dumps(entry, ensure_ascii=False)}")
                corrected_data.append(entry)
                continue
            print(f"[Paiboonæ­£è¦åŒ–å‰] {entry['paiboon']}")
            norm_entry = dict(entry)
            norm_entry["paiboon"] = self.paiboon_normalize(norm_entry["paiboon"], norm_entry)
            print(f"[Paiboonæ­£è¦åŒ–å¾Œ] {norm_entry['paiboon']}")
            single_entry = {
                "thai": norm_entry["thai"],
                "paiboon": norm_entry["paiboon"],
                "meaning": norm_entry["meaning"]
            }
            print(f"[ChatGPTè£œæ­£å‰] {json.dumps(single_entry, ensure_ascii=False)}")
            retry = 0
            max_retry = 1
            while retry < max_retry:
                try:
                    response = self.client.chat.completions.create(
                        model="gpt-4o",
                        messages=[
                            {"role": "system", "content": rules},
                            {"role": "user", "content": json.dumps(single_entry, ensure_ascii=False)}
                        ],
                        temperature=0,
                        top_p=1,
                        max_tokens=128,
                        tools=[{"type": "function", "function": function_schema}],
                        tool_choice="auto"
                    )
                    msg = response.choices[0].message
                    if getattr(msg, "tool_calls", None):
                        args = msg.tool_calls[0].function.arguments
                        result = json.loads(args) if isinstance(args, str) else args
                    else:
                        if msg.content is None:
                            raise ValueError("OpenAIå¿œç­”ã®contentãŒNoneã§ã™")
                        json_match = re.search(r'\{[\s\S]*\}', msg.content)
                        if json_match:
                            result = json.loads(json_match.group(0))
                        else:
                            raise ValueError("No JSON found in response content")
                    if isinstance(result, dict) and all(k in result for k in ["thai", "paiboon", "meaning"]):
                        print(f"[ChatGPTè£œæ­£å¾Œ] {json.dumps(result, ensure_ascii=False)}")
                        corrected_data.append(result)
                        break
                    else:
                        raise ValueError("Result missing required keys")
                except Exception as e:
                    print(f"âš ï¸ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)} (ãƒªãƒˆãƒ©ã‚¤{retry+1}/{max_retry})")
                    retry += 1
                    if retry == max_retry:
                        print(f"âš ï¸ æœ€çµ‚ã‚¨ãƒ©ãƒ¼è©³ç´°: {str(e)} å…¥åŠ›: {json.dumps(single_entry, ensure_ascii=False)}")
                        corrected_data.append(entry)
                        break
        if not all(isinstance(item, dict) and all(k in item for k in ["thai", "paiboon", "meaning"]) for item in corrected_data):
            print("âš ï¸ æˆ»ã‚Šå€¤ã®å‹ãŒä¸æ­£ã§ã™ã€‚å…ƒã®ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã—ã¾ã™ã€‚")
            return data
        return corrected_data

    def _translate_to_english(self, text: str) -> str:
        """æ—¥æœ¬èªã‹ã‚‰è‹±èªã«ç¿»è¨³ï¼ˆãƒ¬ãƒ¼ãƒˆãƒªãƒŸãƒƒãƒˆæ™‚ã¯10ç§’å¾…ã£ã¦1å›ãƒªãƒˆãƒ©ã‚¤ï¼‰"""
        translator = MyMemoryTranslator(source="ja-JP", target="en-GB")
        try:
            result = translator.translate(text)
            time.sleep(0.5)  # Googleç¿»è¨³APIã®ãƒ¬ãƒ¼ãƒˆãƒªãƒŸãƒƒãƒˆå›é¿
            return result
        except Exception as e:
            msg = str(e)
            if "too many requests" in msg.lower() or "you made too many requests" in msg.lower():
                print("âš ï¸ Googleç¿»è¨³APIã®ãƒ¬ãƒ¼ãƒˆãƒªãƒŸãƒƒãƒˆã«é”ã—ã¾ã—ãŸã€‚10ç§’å¾…æ©Ÿã—ã¦ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™ã€‚")
                time.sleep(10)
                try:
                    result = translator.translate(text)
                    time.sleep(0.5)
                    return result
                except Exception as e2:
                    print(f"âŒ å†è©¦è¡Œã§ã‚‚å¤±æ•—: {e2}")
                    raise
            else:
                raise

    def _generate_tts(self, text: str, output_path: Path) -> None:
        """ã‚¿ã‚¤èªã®TTSéŸ³å£°ã‚’ç”Ÿæˆ"""
        tts = gTTS(text=text, lang="th")
        tts.save(str(output_path))

    def _create_anki_package(self, notes: List[Dict[str, str]], media_files: List[Path]) -> Path:
        """Ankiãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ä½œæˆã—ã€éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å«ã‚ã‚‹"""
        # ãƒ¢ãƒ‡ãƒ«å®šç¾©
        model = Model(
            1607392319,
            "Thai Vocab Model",
            fields=[
                {"name": "Thai"},
                {"name": "Phonetic"},
                {"name": "English"},
                {"name": "Audio"},
            ],
            templates=[
                {
                    "name": "Card1",
                    "qfmt": "<h1>{{Phonetic}}</h1>\n<h2>{{Thai}}</h2>\n<hr>\n<h1>{{Audio}}</h1>",
                    "afmt": "<h1>{{Phonetic}}</h1>\n<h2>{{English}}</h2>\n<h2>{{Thai}}</h2>\n<hr>\n<h1>{{Audio}}</h1>",
                },
                {
                    "name": "Card2",
                    "qfmt": "<h1>{{English}}</h1>",
                    "afmt": "<h1>{{English}}</h1>\n<h2>{{Phonetic}}</h2>\n<h2>{{Thai}}</h2>\n<hr>\n<h1>{{Audio}}</h1>",
                },
            ],
            css="""h1, h2 { text-align: center; }"""
        )
        deck_id = abs(hash(self.deck_name)) % (2**31 - 1)
        deck = Deck(deck_id, self.deck_name)
        for note in notes:
            deck.add_note(Note(model, [
                note["Thai"],
                note["Phonetic"],
                note["English"],
                note["Audio"],
            ]))
        # ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«ã®çµ¶å¯¾ãƒ‘ã‚¹ãƒªã‚¹ãƒˆ
        media_paths = [str(p) for p in media_files if Path(p).exists()]
        output_path = self.output_dir / f"{self.deck_name.replace(' ', '_')}.apkg"
        pkg = Package(deck, media_files=media_paths)
        pkg.write_to_file(str(output_path))
        print(f"âœ… Ankiãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ç”Ÿæˆå®Œäº†: {output_path} (ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(media_paths)})")
        return output_path

    def build(self, data: List[Dict[str, str]]) -> Path:
        """ãƒ‡ãƒƒã‚­ã‚’ãƒ“ãƒ«ãƒ‰"""
        # ç©ºã®ãƒ‡ãƒ¼ã‚¿ã‚„nullå€¤ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        valid_data = []
        for item in data:
            if (item.get("thai") and item.get("paiboon") and 
                isinstance(item["thai"], str) and isinstance(item["paiboon"], str) and
                item["thai"].strip() and item["paiboon"].strip()):
                valid_data.append(item)
            else:
                print(f"âš ï¸ ç„¡åŠ¹ãªãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ã‚­ãƒƒãƒ—: {item}")

        if not valid_data:
            print("âŒ æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return None

        print(f"\nğŸ“ ãƒ‡ãƒƒã‚­ç”Ÿæˆå¯¾è±¡ä»¶æ•°: {len(valid_data)} ä»¶")

        # OCRãƒ‡ãƒ¼ã‚¿ã‚’ä¿®æ­£
        if self.use_paiboon_correction:
            corrected_data = self._correct_paiboon(valid_data)
        else:
            corrected_data = valid_data

        # ç¿»è¨³ã¨TTSç”Ÿæˆ
        notes = []
        media_files = []
        total = len(corrected_data)
        for idx, item in enumerate(corrected_data, 1):
            try:
                print(f"[é€²æ—] {idx}/{total} ({(idx/total)*100:.1f}%) - thai: {item['thai']}")
                # è‹±èªã«ç¿»è¨³
                english = self._translate_to_english(item["meaning"])
                # TTSéŸ³å£°ã‚’ç”Ÿæˆ
                tts_path = self.temp_dir / f"{item['thai']}.mp3"
                self._generate_tts(item["thai"], tts_path)
                media_files.append(tts_path)
                # ãƒãƒ¼ãƒˆã‚’ä½œæˆ
                notes.append({
                    "Thai": item["thai"],
                    "Phonetic": item["paiboon"],
                    "English": english,
                    "Audio": f"[sound:{tts_path.name}]"
                })
            except Exception as e:
                print(f"âš ï¸ ãƒãƒ¼ãƒˆç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}")
                continue

        if not notes:
            print("âŒ æœ‰åŠ¹ãªãƒãƒ¼ãƒˆãŒç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸ")
            return None

        # Ankiãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ä½œæˆ
        return self._create_anki_package(notes, media_files)

    def cleanup(self):
        """ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤"""
        import shutil
        shutil.rmtree(self.temp_dir) 